+++
title = "SuperCollider"
chapter = true
weight = 6
+++

* SuperCollider

** SuperCollider

From: [[http://supercollider.github.io][SuperCollider]]

** Basics

SuperCollider is a platform for audio synthesis and algorithmic composition, used by musicians, artists, and researchers working with sound. It is free and open source software available for Windows, macOS, and Linux.

** SuperCollider features three major components:

- *scsynth*, a real-time audio server, forms the core of the platform. It features 400+ unit generators ("UGens") for analysis, synthesis, and processing. Its granularity allows the fluid combination of many known and unknown audio techniques, moving between additive and subtractive synthesis, FM, granular synthesis, FFT, and physical modelling. You can write your own UGens in C++, and users have already contributed several hundred more to the sc3-plugins repository.
- *sclang*, an interpreted programming language. It is focused on sound, but not limited to any specific domain. sclang controls scsynth via Open Sound Control. You can use it for algorithmic composition and sequencing, finding new sound synthesis methods, connecting your app to external hardware including MIDI controllers, network music, writing GUIs and visual displays, or for your daily programming experiments. It has a stock of user-contributed extensions called Quarks.
- *scide* is an editor for sclang with an integrated help system.



** Nodes

From: [[https://composerprogrammer.com/teaching/supercollider/sctutorial/6.3%2520Nodes.html][composerprogrammer.com]]

The Server has a graph of all the running Synths, which may be organised into Groups for convenience. You can see Synths and Groups being created just by looking at the Server graphics.

A Node means a Synth or a Group. Whenever you press command+period you reset the graph, cleaning out all the Synths and Groups you added, that is, clearing all Nodes.

The initial state of the Node graph on the Server looks like this (do command+period first to destroy any existing nodes so you have the starting state):

#+BEGIN_SRC js
s.queryAllNodes //run me to see the Nodes on the Server
#+END_SRC

The two default Nodes are convenient Groups for putting your Synths into.

Group(0) is the absolute root of the tree. All new Synths get placed within this Group somewhere (they might be in subGroups but they will be within the RootNode Group at the top of the hierarchy).

#+BEGIN_SRC js
r=RootNode.new; //this gets a reference to Group(0)
#+END_SRC

Group(1) was added as an additional default to receive all created Synths, to avoid cluttering the base of the tree.

#+BEGIN_SRC js
Group.basicNew(s, 1); //this gets a reference to Group(1)
#+END_SRC




** Find recordings folder

#+BEGIN_SRC js
thisProcess.platform.recordingsDir;
#+END_SRC



** Synthesis techniques


Introduction to sound design (origin, definition, procedures, application fields).

#+BEGIN_QUOTE
SuperCollider example:
Creating a sine wave
#+END_QUOTE


#+BEGIN_SRC js
{SinOsc.ar(440, 0, 0.3)}.play
#+END_SRC

#+BEGIN_QUOTE
Additive synthesis
#+END_QUOTE
#+BEGIN_SRC js
{SinOsc.ar(440, 0, 0.4)+SinOsc.ar(660, 0, 0.3)}.play;
#+END_SRC

#+BEGIN_QUOTE
Subtractive synthesis
#+END_QUOTE

#+BEGIN_SRC js
{LPF.ar(Saw.ar(440, 0.4), [3520, 4400, 5280], 0.3)}.play;
#+END_SRC

#+BEGIN_QUOTE
Granular synthesis
#+END_QUOTE

#+BEGIN_SRC js

SynthDef(\granular, {|out = 0, trig = 1, dur = 0.1, sndbuf, pos = 0.2,
rate = 1, pan = 0, amp = 0.4|
var env, source;
env = EnvGen.kr(Env.adsr, 1, doneAcion: 2);
source = Out.ar(out, GrainBuf.ar(2, Impulse.kr(trig), dur, sndbuf, rate, pos, 2,
pan, envbuf) * env)
}).add;

#+END_SRC



** Input Devices


Musical gestures can be expressed through a wide range of body
movements. Dozens of input devices have been developed to capture
these gestures. (Roads 1996: 625)

#+BEGIN_QUOTE
Switch
Push buttons
Linear potentiometer or fader
Trackball
Joystick
Game Paddles
etc
#+END_QUOTE
** Instrument design


[[http://bela.io][Bela]]


Capacitive touch sensor-raspberry pi

[[https://learn.adafruit.com/mpr121-capacitive-touch-sensor-on-raspberry-pi-and-beaglebone-black/overview][MPR121]]




** Mapping the Data from the Input Device

The message coming from digital input devices are streams of binary
numbers. A microprocessor inside the receiving synthesizer must decode
these streams before commanding the synthesis engine  to emit
sound. (Roads 1996: 625)



   
** Algorithmic Composition examples

#+BEGIN_SRC js

// Collins Cellular automata

// =====================================================================
// SuperCollider Workspace
// =====================================================================

s.boot
(
SynthDef(\cellularautomataexample,{arg freq=440, amp=0.1; 

Out.ar(0,amp*Line.kr(1,0,0.2,doneAction:2)*LPF.ar(LFSaw.ar(freq),Line.kr(5000,1000,0.2)))

}).send(s)

)

(
var a, ca; 
var diatonic= #[0,2,4,5,7,9,11]; 
var w, ms; 
var r; 

w= GUI.window.new("cellular automata", Rect(100,300,300,100));
ms= GUI.multiSliderView.new(w,Rect(20,0,210,100));
ms.indexThumbSize_(10.0);
ms.xOffset_(0.0);
w.front;


a= Array.rand(21,0.0,1.0); //starting data array

ms.value_(a); //initialise view

//function for updating the current array
ca= {|array|  
var b; 

b= array.copy; 

b= array.collect{|val,i| var tmp, noise= 1.0.rand; tmp=(noise*array.wrapAt(i-1)) + ((1.0-noise)*array.wrapAt(i+1)); if(0.1.coin,1.0.rand,tmp)}; 

b
};

r= {
	
	//iterations of CA function
	inf.do{
		
		a= ca.value(a); //update line using cellular automata rules
		
		//a.postln;
		{ms.value_(a);}.defer;
		
		a.do{|val,i| if(val>0.7,{Synth(\cellularautomataexample, [\freq, (diatonic.wrapAt(i) + ((i.div(7))*12) + 48).midicps, \amp, 0.1])}); }; 
		
		0.25.wait;
	}

}.fork; 

w.onClose_({r.stop;});

);

 

#+END_SRC

