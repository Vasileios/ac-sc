[
{
	"uri": "https://vasileios.github.io/ac-sc/",
	"title": "AC",
	"tags": [],
	"description": "",
	"content": "define _foo  Algorithmic Composition Algorithm is:\n A set of mathematical instructions that must be followed in a fixed order, and that, especially if given to a computer, will help to calculate an answer to a mathematical problem [1]. A systematic procedure that produces – in a finite number of steps the answer to a question or the solution of a problem [2]. [...] (especially computing) a set of rules that must be followed when solving a particular problem [4]. (Nierhaus 2009 p.2)  Primary principles of automated information processing can already be found in the 13th century. Through the works of Charles Babbage and Ada Lovelace, The history of algorithmic composition has its beginning shortly after the turn of the first millennium with a system developed by Guido of Arezzo enabling the generation of melodic material from texts, spans over the application of algorithmic principles in the developing complex polyphony and is also found in the “composition machines” of Athanasius Kircher in the Baroque period. Furthermore, first applications of algorithms for compositional tasks can be found in the popular “musical dice game” in the 18th century.\nLejaren Hiller at the Experimental Music Studio to Brian Eno’s generative music.\n Markov models  Markov models are for the most part employed in the field of style imitation, but also, for example by Hiller and Xenakis, for applications of genuine composition.\n Generative grammars  Chomsky's generative grammars generation of musical structure\n Transition networks  David Cope’s program “EMI” “EMI” generates style imitations after having analyzed a sufficient number of compositions of a particular genre.\nhttp://www.computerhistory.org/atchm/algorithmic-music-david-cope-and-emi/\n chaos and self-similarity  Fractals, Lindenmayer systems\n Genetic algorithms   Cellular automata   Neural networks   Artificial intelligence  Nierhaus 2009 (Algorithmic Composition),\nRoads 1996 (Computer Music Tutorial)\nSound Design Summarise Farnell 2010, Sigman 2011, Tolonen et al. 1998.\nSuperCollider From: SuperCollider\nBasics SuperCollider is a platform for audio synthesis and algorithmic composition, used by musicians, artists, and researchers working with sound. It is free and open source software available for Windows, macOS, and Linux.\nSuperCollider features three major components:  scsynth, a real-time audio server, forms the core of the platform. It features 400+ unit generators (\"UGens\") for analysis, synthesis, and processing. Its granularity allows the fluid combination of many known and unknown audio techniques, moving between additive and subtractive synthesis, FM, granular synthesis, FFT, and physical modelling. You can write your own UGens in C++, and users have already contributed several hundred more to the sc3-plugins repository. sclang, an interpreted programming language. It is focused on sound, but not limited to any specific domain. sclang controls scsynth via Open Sound Control. You can use it for algorithmic composition and sequencing, finding new sound synthesis methods, connecting your app to external hardware including MIDI controllers, network music, writing GUIs and visual displays, or for your daily programming experiments. It has a stock of user-contributed extensions called Quarks. scide is an editor for sclang with an integrated help system.  Nodes From: composerprogrammer.com\nThe Server has a graph of all the running Synths, which may be organised into Groups for convenience. You can see Synths and Groups being created just by looking at the Server graphics.\nA Node means a Synth or a Group. Whenever you press command+period you reset the graph, cleaning out all the Synths and Groups you added, that is, clearing all Nodes.\nThe initial state of the Node graph on the Server looks like this (do command+period first to destroy any existing nodes so you have the starting state):\ns.queryAllNodes //run me to see the Nodes on the Server  The two default Nodes are convenient Groups for putting your Synths into.\nGroup(0) is the absolute root of the tree. All new Synths get placed within this Group somewhere (they might be in subGroups but they will be within the RootNode Group at the top of the hierarchy).\nr=RootNode.new; //this gets a reference to Group(0)  Group(1) was added as an additional default to receive all created Synths, to avoid cluttering the base of the tree.\nGroup.basicNew(s, 1); //this gets a reference to Group(1)  Find recordings folder thisProcess.platform.recordingsDir;  Synthesis techniques Introduction to sound design (origin, definition, procedures, application fields).\n  SuperCollider example:  Creating a sine wave  {SinOsc.ar(440, 0, 0.3)}.play    Additive synthesis  {SinOsc.ar(440, 0, 0.4)+SinOsc.ar(660, 0, 0.3)}.play;    Subtractive synthesis  {LPF.ar(Saw.ar(440, 0.4), [3520, 4400, 5280], 0.3)}.play;    Granular synthesis  SynthDef(\\granular, {|out = 0, trig = 1, dur = 0.1, sndbuf, pos = 0.2, rate = 1, pan = 0, amp = 0.4| var env, source; env = EnvGen.kr(Env.adsr, 1, doneAcion: 2); source = Out.ar(out, GrainBuf.ar(2, Impulse.kr(trig), dur, sndbuf, rate, pos, 2, pan, envbuf) * env) }).add;  Input Devices Musical gestures can be expressed through a wide range of body movements. Dozens of input devices have been developed to capture these gestures. (Roads 1996: 625)\n  Switch  Push buttons  Linear potentiometer or fader  Trackball  Joystick  Game Paddles  etc  Instrument design Bela\nCapacitive touch sensor-raspberry pi\nMPR121\nMapping the Data from the Input Device The message coming from digital input devices are streams of binary numbers. A microprocessor inside the receiving synthesizer must decode these streams before commanding the synthesis engine to emit sound. (Roads 1996: 625)\nRemote Control kdnnc dkncknc dkcknkndkc dbccjd\niPython Choose Python to see the code.\n  Choose Python to see the code.  Introduction to Python (https://www.python.org/doc/).\n  Python  # Python 3: Fibonacci series up to n def fib(n): a, b = 0, 1 while a \u0026lt; n: print(a, end=' ') a, b = b, a+b print() fib(1000)  IPython-notebook  IPython notebook is used to analyse data and for data visualisation.   IPython is the component in the toolset that ties everything together; it provides a robust and productive environment for interactive and exploratory computing.   ipython noteboook uses a client-server model. This makes it possible to interact with ipython from several different environments. For example, emacs or a web browser.  For more info see: https://ipython.org\nTwo other key components are Jupyter Notebooks and Anaconda. Jupyter provides Mathematica like notebooks and Anaconda is a package management system.\nJupyter Notebooks, originally called IPython Notebooks,and it commonly used for improving the reproducibility and accessiblity of scientific research.\nOther math/science/data oriented Python tools  Scikit - machine learning Scikit-image \u0026 PIL/Pillow - image processing Blaze - data transformation pipelines \u0026 simplified interactions with various data stores Bokeh - Interactive web visualisations Sympy - symbolic algebra (also see Sage) YT - for analysing and visualising volumetric data Numba - a very easy to use JIT compiler (just import it and put @jit annotation on functions you want compiled) and for dealing with genuinely big data there is PySpark and Ibis.  Install ipython on emacs: First install anaconda: https://www.continuum.io/downloads check your python version in terminal python --version i.e 3.5, and download anaconda3.\nAfter downloaded anaconda open terminal and cd to anacoda3 directory and type:\n  Choose Shell to see the code  bash Anaconda3-4.3.0-MacOSX-x86_64.sh  press yes for anaconda3 to add the PATH to your /.bash_profile/\nThe next step is to:\n install ipython on emacs. One of the packages is called ein and you can install it through melpa.  copy ein.el and ein.py to your emacs upload directory\n open =.emacs.d= and write    Choose emacs-lisp to see the code  (require 'ein)  Start IPython notebook server. Go to terminal and write: jupyter notebook then copy the token and paste it as the password to login to the server.\nOn emacs hit M-x ein:notebooklist-login and press return to use the localhost:8888, server and use the token (password) to login.\ni.e password: 8b6cae64f7dbcfc425a2dsf30cretfdfc7d730dcba9180ab8\nTerm output example\n  Choose Shell to see the output  [I 01:49:54.596 NotebookApp] Serving notebooks from local directory: /Users/usr_name [I 01:49:54.596 NotebookApp] 0 active kernels [I 01:49:54.597 NotebookApp] The Jupyter Notebook is running at: http://localhost:8888/?token8b6cae64f7dbcfc425a2dsf30cretfdfc7d730dcba9180ab8 [I 01:49:54.597 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation). [C 01:49:54.626 NotebookApp] Copy/paste this URL into your browser when you connect for the first time, to login with a token: http://localhost:8888/?token=8b6cae64f7dbcfc425a2dsf30cretfdfc7d730dcba9180ab8  If you successfully logged in to the server;\nHit M-x ein:notebooklist-open to open the notebook list. This will open a notebook list buffer.\nIn the notebook list buffer, you can open notebooks by hitting [Open], [Dir] for directories, create new notebook [New notebook], delete notebook [Delete].\nNOTE* You can also check ob-python package for *source code block ipython in org-mode\nYou can start testing ipython using these examples: particle-physics-playground-playground-52de62d\n  CERN examples: particle-physics-playground-playground-52de62d  Sonifying ems (muons) - ipython - SuperCollider in emacs Editor: Emacs Version 24.5 (9.0)\nIpython package ein on MELPA\nSuperCollider 3.7\nData sonification experiment on particle-physics-playground.\nFor more info see here:\nparticle-physics-playground\n Sending OSC messages to other application  to send osc messages to other application install python-osc library\nIn this case I use SuperCollider port 57120\n  Choose SuperCollider  // BA 28022017 // Testing osc communication - Receiving data from ipython - 'CMS' (Compact Muon Solenoid) __ s.boot // boot the server s.record // record s.stopRecording // stop recording // create synthdef ( SynthDef(\\ipythontest, {| freq = 440, gate = 1, amp = 0.5, out = 0| var env, source; env = EnvGen.kr(Env.adsr, 1, doneAction:2); //source = SinOsc.ar(freq*2, 0, amp); source = SinOsc.ar(SinOsc.ar(freq*2, freq*4, freq*2), 0, amp); // source = UseWhateverGen.ar(); Out.ar(out, Pan2.ar(source*env, 0))!2 }).add; ~x=Synth(\\ipythontest, [\\freq, 440, \\amp, 0.5]); // run the synth // set osc ~a = OSCdef(\\oscTest, { | ... msg | msg.postln; ~x.set(\\freq, msg, \\amp, 0.9); //~muons = msg [0] [1..]; //~muons.postln; // use the osc messages (msg) for the frequency }, '/print' // OSCmessage name ); )    ipython notebook    Choose Python  #VA_exp_280217_001 #Import libraries numpy, matplotlib, pythonosc In [1] import numpy as np import matplotlib.pylab as plt from IPython import get_ipython get_ipython().run_line_magic('matplotlib', 'inline') In [2] #from __future__ import print_function #from __future__ import division import sys sys.path.append(\u0026quot;../particle-physics-playground-Sonification-Example_001/tools/\u0026quot;) #from draw_objects3D import * import cms_tools as cms  In [3] infile = open('../particle-physics-playground-Sonification-Example_001/data/small_cms_test_file.dat') collisions = cms.get_collisions(infile) number_of_collisions = len(collisions) print (\u0026quot;# of proton-proton collisions: %d\u0026quot; % (number_of_collisions)) # of proton-proton collisions: 10 In [4] print (collisions[0]) [[[88.9127, 32.9767, -75.1939, 29.541, -1.0], [79.2211, -58.6558, 49.1723, 13.5915, -1.0], [43.313, -5.9129, 40.0892, 12.0431, -1.0], [274.8094, -21.4194, 27.5639, -272.4152, -1.0], [26.6201, 0.5268, -24.7563, -7.4046, 0.0]], [[15.7375, 1.4793, -15.2566, -3.5645, -1]], [], [[52.364, 17.4983, -45.4233, 19.3009], [10.2904, -1.4633, 10.0887, 1.4035]], [44.9415, 0.422]] In [5] print (len(collisions[0])) 5 In [6] METx = collisions[0][4][0] METy = collisions[0][4][1] print (\u0026quot;MET x: %f\u0026quot; % (METx)) print (\u0026quot;MET y: %f\u0026quot; % (METy)) MET x: 44.941500 MET y: 0.422000 In [7] print (\u0026quot;# of jets: %d\u0026quot; % (len(collisions[0][0]))) print (\u0026quot;# of muons: %d\u0026quot; % (len(collisions[0][1]))) print (\u0026quot;# of electrons: %d\u0026quot; % (len(collisions[0][2]))) print (\u0026quot;# of photons: %d\u0026quot; % (len(collisions[0][3]))) # of jets: 5 # of muons: 1 # of electrons: 0 # of photons: 2 In [8] jets,muons,electrons,photons,met = collisions[0] In [9] E,px,py,pz,btag = jets[0] print (\u0026quot;E: %8.4f\u0026quot; % (E)) print (\u0026quot;px: %8.4f\u0026quot; % (px)) print (\u0026quot;py: %8.4f\u0026quot; % (py)) print (\u0026quot;pz: %8.4f\u0026quot; % (pz)) print (\u0026quot;btag: %8.4f\u0026quot; % (btag)) E: 88.9127 px: 32.9767 py: -75.1939 pz: 29.5410 btag: -1.0000 In [10] E,px,py,pz,q = muons[0] print (\u0026quot;E: %8.4f\u0026quot; % (E)) print (\u0026quot;px: %8.4f\u0026quot; % (px)) print (\u0026quot;py: %8.4f\u0026quot; % (py)) print (\u0026quot;pz: %8.4f\u0026quot; % (pz)) print (\u0026quot;q: %8.4f\u0026quot; % (q)) E: 15.7375 px: 1.4793 py: -15.2566 pz: -3.5645 q: -1.0000 In [11] E,px,py,pz = photons[0] print (\u0026quot;E: %8.4f\u0026quot; % (E)) print (\u0026quot;px: %8.4f\u0026quot; % (px)) print (\u0026quot;py: %8.4f\u0026quot; % (py)) print (\u0026quot;pz: %8.4f\u0026quot; % (pz)) E: 52.3640 px: 17.4983 py: -45.4233 pz: 19.3009 In [0] # Plot the quantities plt.figure(figsize=(16,4)) plt.subplot(1,3,1) plt.hist(njets,bins=5,range=(0,5)) plt.xlabel(r'# of jets') plt.ylabel('# entries') plt.subplot(1,3,2) plt.hist(jets_E,bins=25,range=(0,400)) plt.xlabel(r'Jet energy [GeV]') plt.ylabel('# entries') plt.subplot(1,3,3) plt.hist(muons_E,bins=25,range=(0,400)) plt.xlabel(r'Muon energy [GeV]') plt.ylabel('# entries') h1: Watch an example In [0] from IPython.display import YouTubeVideo YouTubeVideo('UfimSbOr9to') In [13] infile = open('../particle-physics-playground-Sonification-Example_001/data/mc_dy_1000collisions.dat') collisions = cms.get_collisions(infile) # We will use these to store the quantities that we will be plotting later. njets = [] jets_E = [] muons_E = [] photons_E = [] for collision in collisions: jets,muons,electrons,photons,met = collision njets.append(len(jets)) for jet in jets: E,px,py,pz,btag = jet jets_E.append(px) for muon in muons: E,px,py,pz,q = muon muons_E.append(E) for photon in photons: E,px,py,pz = photon photons_E.append(E)  In [18] import time infile = open('../particle-physics-playground-Sonification-Example_001/data/mc_dy_1000collisions.dat') collisions = cms.get_collisions(infile) # We will use these to store the quantities that we will be plotting later. njets = [] jets_E = [] muons_E = [] photons_E = [] for collision in collisions: jets,muons,electrons,photons,met = collision njets.append(len(jets)) for jet in jets: E,px,py,pz,btag = jet jets_E.append(E ) for muon in muons: E,px,py,pz,q = muon muons_E.append(E) for photon in photons: E,px,py,pz = photon photons_E.append(E) # Set up OSC here from pythonosc import osc_message_builder from pythonosc import udp_client # The port for SuperCollider is '57120' client = udp_client.SimpleUDPClient(\u0026quot;127.0.0.1\u0026quot;, 57120) #client.send_message(\u0026quot;/print\u0026quot;, muons_E) # now we can print them out too for i in muons_E: print (\u0026quot;muon was: %d\u0026quot; % i) client.send_message(\u0026quot;/print\u0026quot;, i) time.sleep(0.015) for i in jets_E: print (\u0026quot;jet was: %d\u0026quot; % i) client.send_message(\u0026quot;/print\u0026quot;, i) time.sleep(0.015) for i in photons_E: print (\u0026quot;photon was: %d\u0026quot; % i) client.send_message(\u0026quot;/print\u0026quot;, i) time.sleep(0.015) # # Plot the quantities  YT visualisation An example with enzo data   Choose Python  import os os.chdir('/Users/experiments/yt_pics') import yt ds = yt.load(\u0026quot;/Users/experiments/Enzo_64/DD0043/data0043\u0026quot;) sc = yt.create_scene(ds, lens_type='perspective') # Get a reference to the VolumeSource associated with this scene # It is the first source associated with the scene, so we can refer to it # using index 0. source = sc[0] # Set the bounds of the transfer function source.tfh.set_bounds((3e-31, 5e-27)) # set that the transfer function should be evaluated in log space source.tfh.set_log(True) # Make underdense regions appear opaque source.tfh.grey_opacity = True # Plot the transfer function, along with the CDF of the density field to # see how the transfer function corresponds to structure in the CDF source.tfh.plot('transfer_function.png', profile_field='density') # save the image, flooring especially bright pixels for better contrast sc.save('rendering2.png', sigma_clip=6.0)  For 3D modeling yt see here:\nData Visualisation 3D\nIpython - realtime data Watching the number of flights on your emacs:\nThis experiment tested on python 3.5 and emacs - ipython notebook (ein).\nFor ipython notebook installation see this webpage ipython.\nTo run this example you need to install some external modes\nrequests and BeautifulSoup\nIf you use pip (recommended) open the terminal and type\n  Choose Shell  $ pip install requests  $ pip install beautifulsoup4  Go to the web page to scrape the number of flights\nhttps://www.flightradar24.com/56.16,-49.51/7\nThe number is updated every 8 seconds.\nTo be able to collect the number of flights in real time, go and find the .js file in the webpage. To find the js file go to: Chrome - more tools- developer tools - network - there you'll find the requests under the name feed.js.\nNow, run the below code in you ipython notebook. (code taken from here)\n  Choose Python  import requests from bs4 import BeautifulSoup import time def get_count(): url = \u0026quot;https://data-live.flightradar24.com/zones/fcgi/feed.js?bounds=59.09,52.64,-58.77,-47.71\u0026amp;faa=1\u0026amp;mlat=1\u0026amp;flarm=1\u0026amp;adsb=1\u0026amp;gnd=1\u0026amp;air=1\u0026amp;vehicles=1\u0026amp;estimated =1\u0026amp;maxage=7200\u0026amp;gliders=1\u0026amp;stats=1\u0026quot; # Request with fake header, otherwise you will get an 403 HTTP error r = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'}) # Parse the JSON data = r.json() counter = 0 # Iterate over the elements to get the number of total flights for element in data[\u0026quot;stats\u0026quot;][\u0026quot;total\u0026quot;]: counter += data[\u0026quot;stats\u0026quot;][\u0026quot;total\u0026quot;][element] return counter while True: print(get_count()) time.sleep(8)  Watch here a screen capture\n"
},
{
	"uri": "https://vasileios.github.io/ac-sc/logo/",
	"title": "",
	"tags": [],
	"description": "",
	"content": "  */--  /* @licstart The following is the entire license notice for the JavaScript code in this tag. Copyright (C) 2012-2017 Free Software Foundation, Inc. The JavaScript code in this tag is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License (GNU GPL) as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version. The code is distributed WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU GPL for more details. As additional permission under GNU GPL version 3 section 7, you may distribute non-source (e.g., minimized or compacted) forms of that code without the copy of the GNU GPL normally required by section 4, provided you include this license notice and a URL through which recipients can access the Corresponding Source. @licend The above is the entire license notice for the JavaScript code in this tag. */ *///--         "
},
{
	"uri": "https://vasileios.github.io/ac-sc/logo/",
	"title": "",
	"tags": [],
	"description": "",
	"content": "../images/logo.jpg\n"
},
{
	"uri": "https://vasileios.github.io/ac-sc/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://vasileios.github.io/ac-sc/",
	"title": "Documentation for Hugo Learn Theme",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://vasileios.github.io/ac-sc/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]